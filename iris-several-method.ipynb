{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using several classifiers and tuning parameters - Parameters grid\n",
    "[From official `scikit-learn` documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html)\n",
    " \n",
    "\n",
    "Example of usage of the ***model selection*** features of `scikit-learn` and comparison of several classification methods.\n",
    "1. import a sample dataset \n",
    "1. split the dataset into two parts: train and test\n",
    "    - the *train* part will be used for training and validation (i.e. for *development*)\n",
    "    - the *test* part will be used for test (i.e. for *evaluation*)\n",
    "    - the fraction of test data will be _ts_ (a value of your choice between 0.2 and 0.5)\n",
    "1. the function `GridSearchCV` iterates a cross validation experiment to train and test a model with different combinations of paramater values\n",
    "    - for each parameter we set a list of values to test, the function will generate all the combinations\n",
    "    - we choose a *score function* which will be used for the optimization\n",
    "        - e.g. `accuracy_score`, `precision_score`, `cohen_kappa_score`, `f1_score`, see this [page](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) for reference\n",
    "    - the output is a dictionary containing \n",
    "        - the set of parameters which maximize the score \n",
    "        - the test scores\n",
    "1. prepare the parameters for the grid\n",
    "    - it is a list of dictionaries\n",
    "1. set the parameters by cross validation and the *score functions* to choose from\n",
    "1. Loop on scores and, for each score, loop on the model labels (see details below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
      "@author: scikit-learn.org and Claudio Sartori\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "@author: scikit-learn.org and Claudio Sartori\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # uncomment this line to suppress warnings\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "print(__doc__) # print information included in the triple quotes at the beginning\n",
    "\n",
    "# Loading a standard dataset\n",
    "#dataset = datasets.load_digits()\n",
    "#dataset = datasets.fetch_olivetti_faces()\n",
    "#dataset = datasets.fetch_covtype()\n",
    "dataset = datasets.load_iris()\n",
    "#dataset = datasets.load_wine()\n",
    "#dataset = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the environment\n",
    "The `dataset` module contains, among others, a few sample datasets.\n",
    "\n",
    "See this [page](http://scikit-learn.org/stable/datasets/index.html) for reference\n",
    "\n",
    "Prepare the data and the target in X and y. Set `ts`. Set the random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target\n",
    "ts = 0.3\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into the train and test parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 105 examples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=ts, random_state=random_state)\n",
    "print(\"Training on %d examples\" % len(X_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
